{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Features Discrete\n",
    "In previous weeks we have imputed values and made new variables using the `pandas.cut` function to define how to make a single attribute discrete. In this module, let's instead use clustering to convert one or more features into discrete, categorical features (integers). \n",
    "\n",
    "The process will be simple:\n",
    "- Choose a subset of features from the dataset to cluster upon\n",
    "- Cluster the features assuming according to a given algorithm\n",
    "- Replace the features with their discrete cluster labels as a form of discretization\n",
    "- Perform classification using the new feature from the dataset\n",
    "\n",
    "In this notebook, we will investigate simple clustering methods for making the clusters discrete: kmeans, hierarchical agglomerative clustering, and DBSCAN. The dataset we will use comes from our titanic dataset that we have used in the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 882 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      "Survived      882 non-null int64\n",
      "Age           882 non-null float64\n",
      "Parch         882 non-null float64\n",
      "SibSp         882 non-null float64\n",
      "Pclass        882 non-null float64\n",
      "Fare          882 non-null float64\n",
      "Embarked_C    882 non-null float64\n",
      "Embarked_Q    882 non-null float64\n",
      "Embarked_S    882 non-null float64\n",
      "IsMale        882 non-null float64\n",
      "FamilySize    882 non-null float64\n",
      "dtypes: float64(10), int64(1)\n",
      "memory usage: 82.7 KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "\n",
    "df = pd.read_csv('data/titanic.csv') # read in the csv file\n",
    "\n",
    "# 1. Remove attributes that just arent useful for us\n",
    "del df['PassengerId']\n",
    "del df['Name']\n",
    "del df['Cabin']\n",
    "del df['Ticket']\n",
    "\n",
    "# 2. Impute some missing values, grouped by their Pclass and SibSp numbers\n",
    "df_grouped = df.groupby(by=['Pclass','SibSp'])\n",
    "\n",
    "# # now use this grouping to fill the data set in each group, then transform back\n",
    "# fill in the numeric values\n",
    "df_imputed = df_grouped.transform(lambda grp: grp.fillna(grp.median()))\n",
    "# fill in the categorical values\n",
    "df_imputed[['Sex','Embarked']] = df_grouped[['Sex','Embarked']].apply(lambda grp: grp.fillna(grp.mode()))\n",
    "# fillin the grouped variables from original data frame\n",
    "df_imputed[['Pclass','SibSp']] = df[['Pclass','SibSp']]\n",
    "\n",
    "# 4. drop rows that still had missing values after grouped imputation\n",
    "df_imputed.dropna(inplace=True)\n",
    "\n",
    "# 5. Rearrange the columns\n",
    "df_imputed = df_imputed[['Survived','Age','Sex','Parch','SibSp','Pclass','Fare','Embarked']]\n",
    "\n",
    "# perform one-hot encoding of the categorical data \"embarked\"\n",
    "tmp_df = pd.get_dummies(df_imputed.Embarked,prefix='Embarked')\n",
    "df_imputed = pd.concat((df_imputed,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "# replace the current Sex atribute with something slightly more intuitive and readable\n",
    "df_imputed['IsMale'] = df_imputed.Sex=='male' \n",
    "df_imputed.IsMale = df_imputed.IsMale.astype(np.int)\n",
    "\n",
    "# Now let's clean up the dataset\n",
    "if 'Sex' in df_imputed:\n",
    "    del df_imputed['Sex'] # if 'Sex' column still exists, delete it (as we created an ismale column)\n",
    "    \n",
    "if 'Embarked' in df_imputed:    \n",
    "    del df_imputed['Embarked'] # get reid of the original category as it is now one-hot encoded\n",
    "\n",
    "# Finally, let's create a new variable based on the number of family members\n",
    "\n",
    "# traveling with the passenger\n",
    "\n",
    "# notice that this new column did not exist before this line of code--we use the pandas \n",
    "#    syntax to add it in \n",
    "df_imputed['FamilySize'] = df_imputed.Parch + df_imputed.SibSp\n",
    "\n",
    "y = df_imputed['Survived']\n",
    "df_imputed = (df_imputed-df_imputed.mean())/df_imputed.std()\n",
    "df_imputed['Survived'] = y\n",
    "\n",
    "df_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n\n",
    "n\n",
    "For this dataset, it probably makes sense to try and cluster `PClass` and `Fare` together because they have similar information and can likely be combined. It is unclear exactly where to make the classes discrete and how many levels we should make, so we will try a few different parameterizations to investigate this.\n",
    "\n",
    "It also might make sense to make the `Age`, `Parch`, and `SibSp` cariables into a single discrete variable representing clusters of families. Again, we will need to try different parameterizations (numbers of cluster and the algorithm for clustering).\n",
    "\n",
    "## Baseline Classification Performance\n",
    "Let's start by performing 10 fold cross validation and using the raw features in a Random Forest classifer. Let's get the average accuracy of classifying whther a person survives or does not from the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy =  80.5120020429 +- 5.18006400357\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "y = df_imputed['Survived']\n",
    "X = df_imputed[['Age','IsMale','Parch','SibSp','Pclass','Fare']]\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=150,random_state=1)\n",
    "\n",
    "acc = cross_val_score(clf,X,y=y,cv=cv)\n",
    "\n",
    "print (\"Average accuracy = \", acc.mean()*100, \"+-\", acc.std()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let's start with a bit of feature engineering. We will start by using kmeans on `PClass` and `Fare` together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEaCAYAAADQVmpMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21cd7406c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "%matplotlib inline\n",
    "X1 = df_imputed[['Pclass','Fare']].values\n",
    "\n",
    "plt.scatter(X1[:, 1], X1[:, 0]+np.random.random(X1[:, 1].shape)/2, \n",
    "             s=20)\n",
    "plt.xlabel('Fare (normalized)'), plt.ylabel('Class')\n",
    "plt.grid()\n",
    "plt.title('Class Versus Fare')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy (with kmeans for class/fare)=  79.9438202247 +- 4.40761643373\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X1 = df_imputed[['Pclass','Fare']]\n",
    "\n",
    "cls = KMeans(n_clusters=8, init='k-means++',random_state=1)\n",
    "cls.fit(X1)\n",
    "newfeature = cls.labels_ # the labels from kmeans clustering\n",
    "\n",
    "y = df_imputed['Survived']\n",
    "X = df_imputed[['Age','IsMale','Parch','SibSp']]\n",
    "X = np.column_stack((X,pd.get_dummies(newfeature)))\n",
    "\n",
    "acc = cross_val_score(clf,X,y=y,cv=cv)\n",
    "\n",
    "print (\"Average accuracy (with kmeans for class/fare)= \", acc.mean()*100, \"+-\", acc.std()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-35170fde5ac3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-35170fde5ac3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    So it seems that the average accuracy of the folds has stayed about the same, but the deviation from the mean has been considerably decreased. Let's now try adding in different discretization of the features.\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "So it seems that the average accuracy of the folds has stayed about the same, but the deviation from the mean has been considerably decreased. Let's now try adding in different discretization of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "X2 = df_imputed[['Age','Parch','SibSp']]\n",
    "\n",
    "cls = KMeans(n_clusters=8, init='k-means++',random_state=1)\n",
    "cls.fit(X2)\n",
    "newfeature = cls.labels_ # the labels from kmeans clustering\n",
    "\n",
    "y = df_imputed['Survived']\n",
    "X = df_imputed[['IsMale','Pclass','Fare']]\n",
    "X = np.column_stack((X,pd.get_dummies(newfeature)))\n",
    "\n",
    "acc = cross_val_score(clf,X,y=y,cv=cv)\n",
    "\n",
    "print (\"Average accuracy (with kmeans for Age/Family)= \", acc.mean()*100, \"+-\", acc.std()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This discretization actually helps increase the accuracy on average, but not really helping in the lowering of the deviation from the mean. What if we combine the different clusterings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the first clustering\n",
    "cls_fare = KMeans(n_clusters=8, init='k-means++',random_state=1)\n",
    "cls_fare.fit(X1)\n",
    "newfeature_fare = cls_fare.labels_ # the labels from kmeans clustering\n",
    "\n",
    "# append on the second clustering\n",
    "cls_fam = KMeans(n_clusters=8, init='k-means++',random_state=1)\n",
    "cls_fam.fit(X2)\n",
    "newfeature_fam = cls_fam.labels_ # the labels from kmeans clustering\n",
    "\n",
    "y = df_imputed['Survived']\n",
    "X = df_imputed[['IsMale']]\n",
    "X = np.column_stack((X,pd.get_dummies(newfeature_fare),pd.get_dummies(newfeature_fam)))\n",
    "\n",
    "acc = cross_val_score(clf,X,y=y,cv=cv)\n",
    "\n",
    "print (\"Average accuracy = \", acc.mean()*100, \"+-\", acc.std()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems this is not quite as accurate, but we still need to vary the parameters and see what works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "X1 = df_imputed[['Pclass','Fare']]\n",
    "X2 = df_imputed[['Age','Parch','SibSp']]\n",
    "\n",
    "params = []\n",
    "for n_fare in range(4,10):\n",
    "    for n_fam in range(16,19):\n",
    "        # get the first clustering\n",
    "        cls_fare = KMeans(n_clusters=n_fare, init='k-means++',random_state=1)\n",
    "        cls_fare.fit(X1)\n",
    "        newfeature_fare = cls_fare.labels_ # the labels from kmeans clustering\n",
    "\n",
    "        # append on the second clustering\n",
    "        cls_fam = KMeans(n_clusters=n_fam, init='k-means++',random_state=1)\n",
    "        cls_fam.fit(X2)\n",
    "        newfeature_fam = cls_fam.labels_ # the labels from kmeans clustering\n",
    "\n",
    "        y = df_imputed['Survived']\n",
    "        X = df_imputed[['IsMale']]\n",
    "        X = np.column_stack((X,pd.get_dummies(newfeature_fare),pd.get_dummies(newfeature_fam)))\n",
    "\n",
    "        acc = cross_val_score(clf,X,y=y,cv=cv)\n",
    "        params.append((n_fare,n_fam,acc.mean()*100,acc.std()*100)) # save state\n",
    "\n",
    "        print (\"Clusters\",n_fare,n_fam,\"Average accuracy = \", acc.mean()*100, \"+-\", acc.std()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that about the best we can do with these new discretization methods is around 82%. All the models are within one standard deviation of each other, so most clustering in this range are pretty reasonable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_fare=7\n",
    "d_fam=17\n",
    "\n",
    "X1 = df_imputed[['Pclass','Fare']]\n",
    "X2 = df_imputed[['Age','Parch','SibSp']]\n",
    "\n",
    "cls_fare = KMeans(n_clusters=n_fare, init='k-means++',random_state=1)\n",
    "cls_fare.fit(X1)\n",
    "newfeature_fare = cls_fare.labels_ # the labels from kmeans clustering\n",
    "\n",
    "# append on the second clustering\n",
    "cls_fam = KMeans(n_clusters=n_fam, init='k-means++',random_state=1)\n",
    "cls_fam.fit(X2)\n",
    "newfeature_fam = cls_fam.labels_ # the labels from kmeans clustering\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "X2=X2.values\n",
    "plt.scatter(X2[:, 0], X2[:, 1]+np.random.random(X2[:, 1].shape)/2, c=newfeature_fam, cmap=plt.cm.rainbow, s=20, linewidths=0)\n",
    "plt.xlabel('Age (normalized)'), plt.ylabel('Parch')\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(X2[:, 0], X2[:, 2]+np.random.random(X2[:, 1].shape)/2, c=newfeature_fam, cmap=plt.cm.rainbow, s=20, linewidths=0)\n",
    "plt.xlabel('Age (normalized)'), plt.ylabel('SibSp')\n",
    "plt.grid()\n",
    "\n",
    "X1=X1.values\n",
    "plt.figure()\n",
    "plt.scatter(X1[:, 1], X1[:, 0]+np.random.random(X1[:, 0].shape)/2, c=newfeature_fare, cmap=plt.cm.rainbow, s=20, linewidths=0)\n",
    "plt.xlabel('Fare (Normalized)'), plt.ylabel('Class')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can make things simpler by only clustering on one set of attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "params = []\n",
    "for n_fam in range(15,20):\n",
    "\n",
    "    # append on the clustering\n",
    "    cls_fam = KMeans(n_clusters=n_fam, init='k-means++',random_state=1)\n",
    "    cls_fam.fit(X2)\n",
    "    newfeature_fam = cls_fam.labels_ # the labels from kmeans clustering\n",
    "    print (\"processing\")  \n",
    "    y = df_imputed['Survived']\n",
    "    X = df_imputed[['IsMale','Pclass','Fare']]\n",
    "    X = np.column_stack((X,pd.get_dummies(newfeature_fam)))\n",
    "\n",
    "    acc = cross_val_score(clf,X,y=y,cv=cv)\n",
    "    params.append((n_fare,n_fam,acc.mean()*100,acc.std()*100)) # save state\n",
    "\n",
    "    print (\"Clusters\",n_fam,\"Average accuracy = \", acc.mean()*100, \"+-\", acc.std()*100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that the accuracy is fairly stagnant, but has a tight standard deviation. Now, let's also try to replace features using some slightly different clustering algorithms and see what works best for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "X1 = df_imputed[['Pclass','Fare']]\n",
    "\n",
    "params = []\n",
    "for link in ['ward', 'complete', 'average']:\n",
    "    for n_fam in range(13,20):\n",
    "\n",
    "        # append on the clustering\n",
    "        cls_fam = AgglomerativeClustering(n_clusters=n_fam, linkage=link)\n",
    "        cls_fam.fit(X2)\n",
    "        newfeature_fam = cls_fam.labels_ # the labels from kmeans clustering\n",
    "\n",
    "        y = df_imputed['Survived']\n",
    "        X = df_imputed[['IsMale','Pclass','Fare']]\n",
    "        X = np.column_stack((X,pd.get_dummies(newfeature_fam)))\n",
    "\n",
    "        acc = cross_val_score(clf,X,y=y,cv=cv)\n",
    "        params.append((n_fare,n_fam,acc.mean()*100,acc.std()*100)) # save state\n",
    "\n",
    "        print (\"C=\",n_fam,link,\"Average accuracy = \", acc.mean()*100, \"+-\", acc.std()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, all fairly good performances using different types of linkage and also different numbers of clusters. Let's now try DBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "params = []\n",
    "for eps in [0.1, 0.125, 0.15]:\n",
    "    for mpts in range(5,8):\n",
    "\n",
    "        # append on the clustering\n",
    "        cls_fam = DBSCAN(eps=eps, min_samples=mpts)\n",
    "        cls_fam.fit(X2)\n",
    "        newfeature_fam = cls_fam.labels_ # the labels from kmeans clustering\n",
    "\n",
    "        y = df_imputed['Survived']\n",
    "        X = df_imputed[['IsMale','Pclass','Fare']]\n",
    "        X = np.column_stack((X,pd.get_dummies(newfeature_fam)))\n",
    "\n",
    "        acc = cross_val_score(clf,X,y=y,cv=cv)\n",
    "        params.append((n_fare,n_fam,acc.mean()*100,acc.std()*100)) # save state\n",
    "\n",
    "        print (eps,mpts,\"Average accuracy = \", acc.mean()*100, \"+-\", acc.std()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that DBSCAN has good clusterings for this dataset that are able to capture some of the nuances for the attributes. Although this is not spatial data, it is interesting that contiguous clustering helps discretize the data a bit (for a small range of eps and minpts). Even so, the center based clustering also tend to do well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing different clusters\n",
    "Now lets take the best performers from each dataset and show the clustering that they found in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = X2\n",
    "\n",
    "cls = DBSCAN(eps=0.125, min_samples=6)\n",
    "cls.fit(data)\n",
    "dbs_labels = cls.labels_ \n",
    "\n",
    "cls = AgglomerativeClustering(n_clusters=14, linkage='complete')\n",
    "cls.fit(data)\n",
    "hac_labels = cls.labels_ \n",
    "\n",
    "cls = KMeans(n_clusters=17, random_state=1)\n",
    "cls.fit(data)\n",
    "kmn_labels = cls.labels_\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "title = ['DBSCAN','HAC','KMEANS']\n",
    "\n",
    "for i,l in enumerate([dbs_labels,hac_labels,kmn_labels]):\n",
    "    \n",
    "    plt.subplot(3,2,2*i+1)\n",
    "    plt.scatter(data[:, 0], data[:, 1]+np.random.random(data[:, 1].shape)/2, c=l, cmap=plt.cm.rainbow, s=20, linewidths=0)\n",
    "    plt.xlabel('Age (normalized)'), plt.ylabel('Parch')\n",
    "    plt.grid()\n",
    "    plt.title(title[i])\n",
    "    \n",
    "    plt.subplot(3,2,2*i+2)\n",
    "    plt.scatter(data[:, 0], data[:, 2]+np.random.random(data[:, 1].shape)/2, c=l, cmap=plt.cm.rainbow, s=20, linewidths=0)\n",
    "    plt.xlabel('Age (normalized)'), plt.ylabel('SibSp')\n",
    "    plt.grid()\n",
    "    plt.title(title[i])\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"Clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
